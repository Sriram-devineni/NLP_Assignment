{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddd6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is not installed. Attempting to install spaCy to the user site-packages...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "spaCy is not installed and automatic install failed. Please install spaCy manually with: python -m pip install spacy --user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     17\u001b[0m     importlib\u001b[38;5;241m.\u001b[39minvalidate_caches()\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 20\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspaCy is not installed and automatic install failed. Please install spaCy manually with: python -m pip install spacy --user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Try loading the model; if missing, attempt to download it\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: spaCy is not installed and automatic install failed. Please install spaCy manually with: python -m pip install spacy --user"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assignment 3: Comparative & Non-atomic Requirement Analysis\n",
    "Detects superlatives/comparatives and non-atomic requirements in SRS documents\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Load spaCy model for NLP processing\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "class ComparativeNonAtomicAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Comparative and superlative keywords\n",
    "        self.comparatives = [\n",
    "            'better', 'worse', 'faster', 'slower', 'larger', 'smaller',\n",
    "            'higher', 'lower', 'greater', 'lesser', 'more', 'less',\n",
    "            'easier', 'harder', 'stronger', 'weaker', 'cheaper', 'costlier'\n",
    "        ]\n",
    "        \n",
    "        self.superlatives = [\n",
    "            'best', 'worst', 'fastest', 'slowest', 'largest', 'smallest',\n",
    "            'highest', 'lowest', 'greatest', 'least', 'most', 'easiest',\n",
    "            'hardest', 'strongest', 'weakest', 'cheapest', 'optimal',\n",
    "            'maximum', 'minimum', 'optimum'\n",
    "        ]\n",
    "        \n",
    "        # Coordinators that may indicate non-atomic requirements\n",
    "        self.coordinators = ['and', 'or', 'as well as', 'along with', 'plus']\n",
    "        \n",
    "        self.results = {\n",
    "            'comparatives': [],\n",
    "            'superlatives': [],\n",
    "            'non_atomic': []\n",
    "        }\n",
    "        \n",
    "    def detect_comparatives_superlatives(self, text: str, doc_name: str) -> None:\n",
    "        \"\"\"Detect comparative and superlative terms in text\"\"\"\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        for sent_idx, sent in enumerate(doc.sents, 1):\n",
    "            sent_text = sent.text.strip()\n",
    "            sent_lower = sent_text.lower()\n",
    "            \n",
    "            # Check for comparatives\n",
    "            for comp in self.comparatives:\n",
    "                if re.search(r'\\b' + comp + r'\\b', sent_lower):\n",
    "                    self.results['comparatives'].append({\n",
    "                        'document': doc_name,\n",
    "                        'sentence_num': sent_idx,\n",
    "                        'sentence': sent_text,\n",
    "                        'keyword': comp,\n",
    "                        'type': 'comparative'\n",
    "                    })\n",
    "            \n",
    "            # Check for superlatives\n",
    "            for sup in self.superlatives:\n",
    "                if re.search(r'\\b' + sup + r'\\b', sent_lower):\n",
    "                    self.results['superlatives'].append({\n",
    "                        'document': doc_name,\n",
    "                        'sentence_num': sent_idx,\n",
    "                        'sentence': sent_text,\n",
    "                        'keyword': sup,\n",
    "                        'type': 'superlative'\n",
    "                    })\n",
    "    \n",
    "    def detect_non_atomic(self, text: str, doc_name: str) -> None:\n",
    "        \"\"\"Detect non-atomic requirements with coordinators\"\"\"\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        for sent_idx, sent in enumerate(doc.sents, 1):\n",
    "            sent_text = sent.text.strip()\n",
    "            sent_lower = sent_text.lower()\n",
    "            \n",
    "            # Check if sentence contains modal verbs (shall, must, should, will)\n",
    "            # which indicate requirements\n",
    "            modal_verbs = ['shall', 'must', 'should', 'will', 'required', 'needs to']\n",
    "            has_modal = any(modal in sent_lower for modal in modal_verbs)\n",
    "            \n",
    "            if has_modal:\n",
    "                # Check for coordinators\n",
    "                for coord in self.coordinators:\n",
    "                    pattern = r'\\b' + re.escape(coord) + r'\\b'\n",
    "                    if re.search(pattern, sent_lower):\n",
    "                        # Count verbs to estimate number of actions\n",
    "                        verbs = [token for token in sent if token.pos_ == 'VERB']\n",
    "                        \n",
    "                        if len(verbs) >= 2 or coord in ['or', 'and']:\n",
    "                            self.results['non_atomic'].append({\n",
    "                                'document': doc_name,\n",
    "                                'sentence_num': sent_idx,\n",
    "                                'sentence': sent_text,\n",
    "                                'coordinator': coord,\n",
    "                                'verb_count': len(verbs)\n",
    "                            })\n",
    "                            break\n",
    "    \n",
    "    def suggest_improvements(self, item: Dict, item_type: str) -> List[str]:\n",
    "        \"\"\"Suggest improvements for detected issues\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        if item_type in ['comparative', 'superlative']:\n",
    "            sent = item['sentence']\n",
    "            keyword = item['keyword']\n",
    "            \n",
    "            suggestions.append(f\"Original: {sent}\")\n",
    "            suggestions.append(f\"\\nIssue: Contains {item_type} term '{keyword}' which is vague and unmeasurable.\")\n",
    "            suggestions.append(\"\\nSuggestions:\")\n",
    "            suggestions.append(\"1. Replace with specific, measurable criteria:\")\n",
    "            \n",
    "            if keyword in ['faster', 'fast', 'fastest']:\n",
    "                suggestions.append(\"   - 'shall respond within 2 seconds'\")\n",
    "                suggestions.append(\"   - 'shall process requests in less than 100ms'\")\n",
    "            elif keyword in ['better', 'best', 'optimal']:\n",
    "                suggestions.append(\"   - 'shall achieve 99.9% uptime'\")\n",
    "                suggestions.append(\"   - 'shall meet performance benchmark of X operations/second'\")\n",
    "            elif keyword in ['larger', 'smaller', 'largest', 'smallest']:\n",
    "                suggestions.append(\"   - 'shall support files up to 10MB'\")\n",
    "                suggestions.append(\"   - 'shall occupy no more than 500MB of memory'\")\n",
    "            elif keyword in ['more', 'most', 'less', 'least']:\n",
    "                suggestions.append(\"   - Specify exact quantities or percentages\")\n",
    "                suggestions.append(\"   - 'shall provide at least 5 options'\")\n",
    "            else:\n",
    "                suggestions.append(\"   - Define specific metrics and thresholds\")\n",
    "                suggestions.append(\"   - Use quantifiable measures instead of relative terms\")\n",
    "        \n",
    "        elif item_type == 'non_atomic':\n",
    "            sent = item['sentence']\n",
    "            coord = item['coordinator']\n",
    "            \n",
    "            suggestions.append(f\"Original: {sent}\")\n",
    "            suggestions.append(f\"\\nIssue: Non-atomic requirement using coordinator '{coord}'.\")\n",
    "            suggestions.append(\"Multiple requirements combined into one sentence.\")\n",
    "            suggestions.append(\"\\nSuggestions:\")\n",
    "            suggestions.append(\"1. Split into separate, atomic requirements:\")\n",
    "            \n",
    "            # Attempt to split the requirement\n",
    "            parts = re.split(r'\\b' + re.escape(coord) + r'\\b', sent, maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                # Extract the modal verb to reuse\n",
    "                modal_match = re.search(r'\\b(shall|must|should|will)\\b', sent.lower())\n",
    "                modal = modal_match.group(0) if modal_match else 'shall'\n",
    "                \n",
    "                suggestions.append(f\"   REQ-X.1: {parts[0].strip()}\")\n",
    "                suggestions.append(f\"   REQ-X.2: The system {modal} {parts[1].strip()}\")\n",
    "            else:\n",
    "                suggestions.append(\"   - Identify each distinct requirement\")\n",
    "                suggestions.append(\"   - Create separate requirement statements for each\")\n",
    "                suggestions.append(\"   - Assign unique requirement IDs\")\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    def analyze_directory(self, directory_path: str) -> None:\n",
    "        \"\"\"Analyze all text files in directory\"\"\"\n",
    "        path = Path(directory_path)\n",
    "        \n",
    "        if not path.exists():\n",
    "            print(f\"Error: Directory {directory_path} not found\")\n",
    "            return\n",
    "        \n",
    "        # Find all text and requirements files\n",
    "        file_patterns = ['*.txt', '*.srs', '*.req', '*.md']\n",
    "        files = []\n",
    "        for pattern in file_patterns:\n",
    "            files.extend(path.rglob(pattern))\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"No requirement files found in {directory_path}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Found {len(files)} files to analyze\\n\")\n",
    "        \n",
    "        for file_path in files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    content = f.read()\n",
    "                    doc_name = file_path.name\n",
    "                    \n",
    "                    print(f\"Analyzing: {doc_name}\")\n",
    "                    self.detect_comparatives_superlatives(content, doc_name)\n",
    "                    self.detect_non_atomic(content, doc_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    def generate_report(self, output_file: str = 'assignment3_report.txt') -> None:\n",
    "        \"\"\"Generate detailed analysis report\"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"ASSIGNMENT 3: COMPARATIVE & NON-ATOMIC REQUIREMENT ANALYSIS\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Summary statistics\n",
    "            f.write(\"SUMMARY STATISTICS\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "            f.write(f\"Total Comparative Terms Found: {len(self.results['comparatives'])}\\n\")\n",
    "            f.write(f\"Total Superlative Terms Found: {len(self.results['superlatives'])}\\n\")\n",
    "            f.write(f\"Total Non-Atomic Requirements Found: {len(self.results['non_atomic'])}\\n\\n\")\n",
    "            \n",
    "            # Comparative findings\n",
    "            if self.results['comparatives']:\n",
    "                f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "                f.write(\"COMPARATIVE TERMS DETECTED\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                \n",
    "                for idx, item in enumerate(self.results['comparatives'], 1):\n",
    "                    f.write(f\"\\n{idx}. Document: {item['document']}\\n\")\n",
    "                    f.write(f\"   Sentence #{item['sentence_num']}\\n\")\n",
    "                    f.write(f\"   Keyword: '{item['keyword']}'\\n\")\n",
    "                    f.write(f\"   Sentence: {item['sentence']}\\n\")\n",
    "                    f.write(\"\\n   \" + \"-\" * 76 + \"\\n\")\n",
    "                    suggestions = self.suggest_improvements(item, 'comparative')\n",
    "                    f.write(\"   \" + \"\\n   \".join(suggestions) + \"\\n\")\n",
    "                    f.write(\"   \" + \"-\" * 76 + \"\\n\")\n",
    "            \n",
    "            # Superlative findings\n",
    "            if self.results['superlatives']:\n",
    "                f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "                f.write(\"SUPERLATIVE TERMS DETECTED\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                \n",
    "                for idx, item in enumerate(self.results['superlatives'], 1):\n",
    "                    f.write(f\"\\n{idx}. Document: {item['document']}\\n\")\n",
    "                    f.write(f\"   Sentence #{item['sentence_num']}\\n\")\n",
    "                    f.write(f\"   Keyword: '{item['keyword']}'\\n\")\n",
    "                    f.write(f\"   Sentence: {item['sentence']}\\n\")\n",
    "                    f.write(\"\\n   \" + \"-\" * 76 + \"\\n\")\n",
    "                    suggestions = self.suggest_improvements(item, 'superlative')\n",
    "                    f.write(\"   \" + \"\\n   \".join(suggestions) + \"\\n\")\n",
    "                    f.write(\"   \" + \"-\" * 76 + \"\\n\")\n",
    "            \n",
    "            # Non-atomic findings\n",
    "            if self.results['non_atomic']:\n",
    "                f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "                f.write(\"NON-ATOMIC REQUIREMENTS DETECTED\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                \n",
    "                for idx, item in enumerate(self.results['non_atomic'], 1):\n",
    "                    f.write(f\"\\n{idx}. Document: {item['document']}\\n\")\n",
    "                    f.write(f\"   Sentence #{item['sentence_num']}\\n\")\n",
    "                    f.write(f\"   Coordinator: '{item['coordinator']}'\\n\")\n",
    "                    f.write(f\"   Verb Count: {item['verb_count']}\\n\")\n",
    "                    f.write(f\"   Sentence: {item['sentence']}\\n\")\n",
    "                    f.write(\"\\n   \" + \"-\" * 76 + \"\\n\")\n",
    "                    suggestions = self.suggest_improvements(item, 'non_atomic')\n",
    "                    f.write(\"   \" + \"\\n   \".join(suggestions) + \"\\n\")\n",
    "                    f.write(\"   \" + \"-\" * 76 + \"\\n\")\n",
    "            \n",
    "            # Frequency analysis\n",
    "            f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\")\n",
    "            f.write(\"FREQUENCY ANALYSIS\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Count by keyword\n",
    "            comp_freq = defaultdict(int)\n",
    "            for item in self.results['comparatives']:\n",
    "                comp_freq[item['keyword']] += 1\n",
    "            \n",
    "            sup_freq = defaultdict(int)\n",
    "            for item in self.results['superlatives']:\n",
    "                sup_freq[item['keyword']] += 1\n",
    "            \n",
    "            coord_freq = defaultdict(int)\n",
    "            for item in self.results['non_atomic']:\n",
    "                coord_freq[item['coordinator']] += 1\n",
    "            \n",
    "            if comp_freq:\n",
    "                f.write(\"Comparative Terms Frequency:\\n\")\n",
    "                for keyword, count in sorted(comp_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "                    f.write(f\"  {keyword}: {count}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            if sup_freq:\n",
    "                f.write(\"Superlative Terms Frequency:\\n\")\n",
    "                for keyword, count in sorted(sup_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "                    f.write(f\"  {keyword}: {count}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            if coord_freq:\n",
    "                f.write(\"Coordinator Frequency in Non-Atomic Requirements:\\n\")\n",
    "                for coord, count in sorted(coord_freq.items(), key=lambda x: x[1], reverse=True):\n",
    "                    f.write(f\"  {coord}: {count}\\n\")\n",
    "        \n",
    "        print(f\"\\nReport generated: {output_file}\")\n",
    "    \n",
    "    def generate_json_output(self, output_file: str = 'assignment3_results.json') -> None:\n",
    "        \"\"\"Generate JSON output for programmatic access\"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"JSON results saved: {output_file}\")\n",
    "    \n",
    "    def generate_summary_table(self) -> None:\n",
    "        \"\"\"Generate summary table for the report\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"SUMMARY TABLE\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"{'Bad Smell Type':<30} {'Frequency':<15} {'Description':<55}\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Comparative Terms':<30} {len(self.results['comparatives']):<15} {'Vague relative comparisons (better, faster, etc.)':<55}\")\n",
    "        print(f\"{'Superlative Terms':<30} {len(self.results['superlatives']):<15} {'Unmeasurable extremes (best, fastest, optimal)':<55}\")\n",
    "        print(f\"{'Non-Atomic Requirements':<30} {len(self.results['non_atomic']):<15} {'Multiple requirements combined with coordinators':<55}\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"Assignment 3: Comparative & Non-atomic Requirement Analysis\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = ComparativeNonAtomicAnalyzer()\n",
    "    \n",
    "    # Get dataset path from user\n",
    "    dataset_path = input(\"\\nEnter the path to PURE dataset directory (or press Enter for './PURE'): \").strip()\n",
    "    if not dataset_path:\n",
    "        dataset_path = './PURE'\n",
    "    \n",
    "    # Analyze documents\n",
    "    print(\"\\nStarting analysis...\\n\")\n",
    "    analyzer.analyze_directory(dataset_path)\n",
    "    \n",
    "    # Generate outputs\n",
    "    print(\"\\nGenerating reports...\\n\")\n",
    "    analyzer.generate_summary_table()\n",
    "    analyzer.generate_report()\n",
    "    analyzer.generate_json_output()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Analysis complete!\")\n",
    "    print(\"Output files:\")\n",
    "    print(\"  - assignment3_report.txt (Detailed report)\")\n",
    "    print(\"  - assignment3_results.json (JSON data)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
